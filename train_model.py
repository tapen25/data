import os
import glob
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib

# ======== â‘  ãƒ‡ãƒ¼ã‚¿ã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã‚’æŒ‡å®š ========
DATA_ROOT = "./HASC_dataset"  # â† ã‚ãªãŸã®å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã«åˆã‚ã›ã‚‹

# ======== â‘¡ ãƒ•ã‚©ãƒ«ãƒ€åã¨ãƒ©ãƒ™ãƒ«ã®å¯¾å¿œ ========
LABELS = {
    "1_stay": 0,
    "2_walk": 1,
    "4_skip": 2
}

# ======== â‘¢ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿é–¢æ•° ========
def load_csv_files():
    X, y = [], []

    for label_name, label_id in LABELS.items():
        folder_path = os.path.join(DATA_ROOT, label_name)
        persons = glob.glob(os.path.join(folder_path, "person*"))
        for person_folder in persons:
            csv_files = glob.glob(os.path.join(person_folder, "*.csv"))
            for csv_file in csv_files:
                try:
                    # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„ã®ã§æ˜ç¤ºçš„ã«æŒ‡å®š
                    df = pd.read_csv(csv_file, header=None, names=["Time", "AccX", "AccY", "AccZ"])

                    # ãƒ‡ãƒ¼ã‚¿è¡ŒãŒã‚ã‚‹ã‹ç¢ºèª
                    if df.shape[0] < 10:
                        print(f"âš ï¸ Skipped (too short): {csv_file}")
                        continue

                    # ç‰¹å¾´é‡æŠ½å‡º
                    features = extract_features(df)
                    X.append(features)
                    y.append(label_id)

                except Exception as e:
                    print(f"âŒ Error reading {csv_file}: {e}")

    return np.array(X), np.array(y)


# ======== â‘£ ç‰¹å¾´é‡æŠ½å‡ºï¼ˆã‚·ãƒ³ãƒ—ãƒ«çµ±è¨ˆç‰¹å¾´ï¼‰ ========
def extract_features(df):
    feats = []
    for axis in ["AccX", "AccY", "AccZ"]:
        feats.extend([
            df[axis].mean(),
            df[axis].std(),
            df[axis].max(),
            df[axis].min(),
            df[axis].median(),
        ])
    return feats

# ======== â‘¤ ãƒ¡ã‚¤ãƒ³å‡¦ç† ========
def main():
    print("ğŸ“‚ Loading data...")
    X, y = load_csv_files()
    print(f"âœ… Loaded: {len(X)} samples")

    # ======== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ========
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # ======== ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° ========
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # ======== ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ ========
    print("ğŸš€ Training LightGBM model...")
    model = LGBMClassifier(
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        random_state=42
    )
    model.fit(X_train, y_train)

    # ======== è©•ä¾¡ ========
    y_pred = model.predict(X_test)
    print("\n=== Classification Report ===")
    print(classification_report(y_test, y_pred, target_names=["stay", "walk", "skip"]))

    print("\n=== Confusion Matrix ===")
    print(confusion_matrix(y_test, y_pred))

    # ======== ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ========
    os.makedirs("model", exist_ok=True)
    joblib.dump(model, "model/hasc_lgbm.pkl")
    joblib.dump(scaler, "model/scaler.pkl")
    print("ğŸ’¾ Saved model to model/hasc_lgbm.pkl")

if __name__ == "__main__":
    main()
